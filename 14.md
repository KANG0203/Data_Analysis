## 5pg.

Recommender System: Basic idea
- 두 사람 A와 B가 유사하고, A가 item X를 선호하면, B도 X를 선호할 가능성이 높다.(user similarity 측정)
- 두 item X와 Y가 유사하고, A가 item X를 선호하면, A는 Y도 선호할 가능성이 높다.(item similarity 측정)

similiarity 측정 방법
- user와 item을 feature vectors로 표현하고, 그들 간의 coefficient나 cosine similiarity를 계산

## 6pg.

Recommender System: CB vs. CF -> user와 item을 feature vector로 나타내는 방법  

Content-based approach (CB)
- user content - domain specific 예를 들면 movie domain - actor, genre, director, year, synopsis, etc.

Collaborative filtering (CF)
- raiting information - domain independent 예를 들면
- user가 item에 rating(explicit feedback)
- user의 purchase 기록 or item에 대한 click record(implicit feedback)

CF는 상업적 성공을 입증하고, 커뮤니티에서 활발히 연구되었다.  
최근 딥러닝 기술을 이용한 hybrid approaches가 인기를 얻고 있으며, 이는 이 강좌에서 안다룬다.  

## 7pg.

Collaborative filtering (CF)
- user와 item의 관계를 사용
- 관계는 rating matrix로 나타내짐

## 9 ~ 11pg.

k-nearest neighbor: User-base  

Pearson correlation between two users
- 식 잘 보기

## 12pg.

k-nearest neighbor: Item-based
- cosing similiarity 식 보기

## 13pg.

k-nearest neighbor pros
- intuitive(직관적)
- training 필요 없다
- user에게 설명 쉬움

cons
- scalable or accurate 떨어짐
- sparse matrix(행렬 값이 대부분 0)에 대해 좋지 않다

## 15pg.

Matrix factorization
- rating matrix를 user와 item matrices로 분해하여, rating을 생성하는 latent model이 된다

## 19pg.

latent model은 phenomena나 observation을 잘 설명하는 hidden model이다.  

## 20pg.

Latent space
-  user와 item은 shared latent spcae에서 vector로 표현할 수 있다.
-  rating score는 user latent vector와 item latent vector의 dot product 즉 내적으로 생성

## 21pg.

goal -> error를 최소화하는 P와 Q 찾자  

## 22pg.

식 보고 이해  

## 23pg.

Gradient Descent (GD)
- objective func를 최소화하기 위한 1차 최적화 알고리즘
- f(x): x를 최소화활 object func
- random x로 시작하여 현재 지점에서 음의 기울기에 비례하는 크기의 step을 취한다
- 즉 경사가 낮아지는 쪽으로 이동한다 이거임

## 24pg.

MF에 gradient descent 적용한 모습  
derivative rule에 따라서 식 적용하면 뭐 충분히 이해 ㄱㄴ  

## 25pg.

standard GD를 계산하는 것은 힘들다.  

Stochastic Gradient Descent (SGD) for MF -> 비용 적음
- data instance를 무작위로 선택
- 해당 instance와 관련된 기울기 계산
- 구한 기울기로 soln update

## 27pg.

Random walk on graph
- user와 item은 bipartite graph(양방향)로 나타남. user, item은 node이며 rank는 그들 사이의 link이다.
- 알려지지 않은 rating은 random walk로 추정할 수 있고, pagerank 알고리즘과 비슷
- random walk를 통해 i에 도달하는 시도의 분수를 통해 비례적으로 얻을 수 있다.

뒤에 예제 보면 쉽게 이해할 수 있다.  

## 30pg.

Summary and recent trends  

실제로 rating matrices는 매우 희소하다
- MF(or random walk)도 실패 할수 있다.

hybrid approaches는 CB와 CF를 합친다
- multimodal learning
- 딥러닝
- cold-start 추천

다른 이슈
- scalability
- privacy-preserving
- timing
- novelty or diversity

## 31pg.

Data sparsity problem(데이터 희소성 문제) -> 딱히 안중요한듯  
